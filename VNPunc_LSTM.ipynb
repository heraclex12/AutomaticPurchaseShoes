{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VNPunc - LSTM",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1BeUp9ZYiJ8gO-dCbechN05xe_DSjEi0J",
      "authorship_tag": "ABX9TyOq6XO5JnM31WmF1IYNv6MT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heraclex12/AutomaticPurchaseShoes/blob/master/VNPunc_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_IBDGDReQ8S"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "os.chdir('drive/My Drive/vncorenlp/journal_hero')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfuqkE3Vh6FQ"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umFweTcQuTvf"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7b9bRDdeTuI"
      },
      "source": [
        "max_paragraph_leng = 128\n",
        "max_char_leng = 20\n",
        "batch_size = 64\n",
        "WORD_EMBEDDING_SIZE = 512\n",
        "VOCAB_WORD_SIZE = 60000\n",
        "special_tokens = ['<NUM>', '<URL>', '<EMAIL>']\n",
        "punctuation_marks = ['PERIOD', 'COMMA', 'COLON', 'QMARK', 'EXCLAM', 'SEMICOLON', 'O']\n",
        "pad_token = '<PAD>'\n",
        "pad_id = len(punctuation_marks)\n",
        "eos_marks = ['PERIOD', 'QMARK', 'EXCLAM']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXtV-8a5eTwi"
      },
      "source": [
        "train_df = pd.read_csv('punctuation/Novels/train.txt', encoding='utf-8', sep=' ', names=['token', 'label'], keep_default_na=False)\n",
        "test_df = pd.read_csv('punctuation/Novels/test.txt', encoding='utf-8', sep=' ', names=['token', 'label'], keep_default_na=False)\n",
        "valid_df = pd.read_csv('punctuation/Novels/valid.txt', encoding='utf-8', sep=' ', names=['token', 'label'], keep_default_na=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7TyNIq6fdH9"
      },
      "source": [
        "def get_paragraphs(df):\n",
        "  idx = 0\n",
        "  n_tokens = len(df)\n",
        "  paragraphs = []\n",
        "  token_labels = []\n",
        "  while idx < n_tokens and idx >= 0:\n",
        "    sub_df = df.iloc[idx: min(idx+128, n_tokens)]\n",
        "    end_idx = sub_df[sub_df.label.isin(eos_marks)].tail(1).index\n",
        "    if end_idx.empty:\n",
        "      end_idx = -1\n",
        "      paragraph_df = df.iloc[idx:]\n",
        "    else:\n",
        "      end_idx = end_idx.item() + 1\n",
        "      paragraph_df = df.iloc[idx: end_idx]\n",
        "\n",
        "    numeric_labels = paragraph_df.label.apply(lambda l: punctuation_marks.index(l))\n",
        "    paragraphs.append(paragraph_df.token.values.tolist())\n",
        "    token_labels.append(numeric_labels.values.tolist())\n",
        "    idx = end_idx\n",
        "  return paragraphs, token_labels\n",
        "\n",
        "train_pags, train_labels = get_paragraphs(train_df)\n",
        "valid_pags, valid_labels = get_paragraphs(valid_df)\n",
        "test_pags, test_labels = get_paragraphs(test_df)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plz6dGyUj53A",
        "outputId": "9b0a5b0a-3198-4fe8-8aef-c734c34dc8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# setting TPU\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  print('Not use TPU')\n",
        "\n",
        "\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else: # default strategy that works on CPU and single GPU\n",
        "  strategy = tf.distribute.get_strategy()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.123.183.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.123.183.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.123.183.74:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.123.183.74:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i73xrhMLfjc1"
      },
      "source": [
        "import collections\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "__SPIECE_UNDERLINE__ = u\"▁\"\n",
        "\n",
        "def load_vocab(filename):\n",
        "    \"\"\"\n",
        "      Load saved vocab file.\n",
        "    \"\"\"\n",
        "    vocab = collections.OrderedDict()\n",
        "    index = 0\n",
        "    with tf.io.gfile.GFile(filename, \"r\") as reader:\n",
        "        while True:\n",
        "            token = reader.readline().strip()\n",
        "            if not token:\n",
        "                break\n",
        "            token = token.split(\"\\t\")[0]\n",
        "            vocab[token] = index\n",
        "            index += 1\n",
        "    return vocab\n",
        "\n",
        "class Tokenizer():\n",
        "    \"\"\"\n",
        "      Load Word vocabulary and Character vocabulary and convert ids to tokens end otherwise\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab=None, char_vocab=None, do_lower_case=False, unk_id = 1):\n",
        "        \n",
        "        if vocab:\n",
        "            self.vocab = load_vocab(vocab)\n",
        "            self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "\n",
        "        if char_vocab:\n",
        "            self.char_vocab = load_vocab(char_vocab)\n",
        "            self.inv_char_vocab = {v: k for k, v in self.char_vocab.items()}\n",
        "\n",
        "        self.max_input_chars_per_word = 200\n",
        "        self.unk_id = unk_id\n",
        "        self.do_lower_case = do_lower_case\n",
        "\n",
        "    def tokenize(self, text, return_tok_to_orig=True):\n",
        "        text = unicodedata.normalize(\"NFKC\", text)\n",
        "        if self.do_lower_case:\n",
        "            text = text.lower()\n",
        "        result = dict()\n",
        "        tok_to_orig = []\n",
        "        tokens = []\n",
        "        token = \"\"\n",
        "        def _tokenize_token(token):\n",
        "            if token.isnumeric():\n",
        "              token = '<NUM>'\n",
        "            tokens.append(token)\n",
        "            tok_to_orig.append([i-len(token), i])\n",
        "        for i, c in enumerate(text):\n",
        "            if _is_whitespace(c):\n",
        "                if token:\n",
        "                     _tokenize_token(token); token = \"\"\n",
        "            elif _is_punctuation(c):\n",
        "                if token:\n",
        "                     _tokenize_token(token); token = \"\"\n",
        "                tokens.append(c)\n",
        "                tok_to_orig.append([i, i+1])\n",
        "            else:\n",
        "                token += c\n",
        "        if token:\n",
        "            i = len(text)\n",
        "            _tokenize_token(token); token = \"\"\n",
        "        if not return_tok_to_orig:\n",
        "            return tokens\n",
        "        return {\n",
        "            \"tokens\": tokens,\n",
        "            \"tok_to_orig\": tok_to_orig\n",
        "        }\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens, pad=False):\n",
        "        token_ids = [self.vocab[token] if token in self.vocab else self.unk_id for token in tokens ]\n",
        "        if pad:\n",
        "          n_tokens = len(token_ids)\n",
        "          max_len = min(max_paragraph_leng, n_tokens)\n",
        "          return token_ids[:max_len] + [0] * (max_paragraph_leng - max_len)\n",
        "          \n",
        "        return token_ids\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        return [self.inv_vocab[idd] for idd in ids]\n",
        "\n",
        "    def convert_chars_to_ids(self, tokens, pad=False):\n",
        "        def pad_char(char_id):\n",
        "          n_char = len(char_id)\n",
        "          max_len = min(max_char_length, n_char)\n",
        "          return char_id[:max_len] + [0] * (max_char_length - max_len)\n",
        "\n",
        "        if pad:\n",
        "          char_ids = [[self.char_vocab[char] if char in self.char_vocab else self.unk_id for char in token] for token in tokens]\n",
        "          char_ids = list(map(pad_char, char_ids))\n",
        "          max_len = min(max_seq_length, len(tokens))\n",
        "          char_ids = char_ids + [[0] * max_char_length for _ in range(max_seq_length - max_len)]\n",
        "        else:\n",
        "          char_ids = [[self.char_vocab[char] if char in self.char_vocab else self.unk_id for char in token] for token in tokens]\n",
        "\n",
        "        return char_ids\n",
        "\n",
        "\n",
        "    def convert_ids_to_chars(self, ids):\n",
        "        return [[self.inv_char_vocab[idd] for idd in token] for token in ids]\n",
        "\n",
        "def _is_punctuation(char):\n",
        "    \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
        "    cp = ord(char)\n",
        "    if char in string.punctuation:\n",
        "        return True\n",
        "    cat = unicodedata.category(char)\n",
        "    if cat.startswith(\"P\") or cat == \"Sc\" or cat == \"Sk\":\n",
        "        return True\n",
        "    if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
        "        (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def _is_whitespace(char):\n",
        "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
        "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "        return True\n",
        "    cat = unicodedata.category(char)\n",
        "    if cat == \"Zs\" or cat == \"Cc\" or cat == \"Cf\":\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(vocab='gs://spellingchecker/vocab/vocab_punc_uncased.vocab', char_vocab='gs://spellingchecker/vocab/vcorrector-uncased-char.vocab')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwfFPSoCfjZ5"
      },
      "source": [
        "train_input_ids = [tokenizer.convert_tokens_to_ids(train_pag, pad=True) for train_pag in train_pags]\n",
        "test_input_ids = [tokenizer.convert_tokens_to_ids(test_pag, pad=True) for test_pag in test_pags]\n",
        "valid_input_ids = [tokenizer.convert_tokens_to_ids(valid_pag, pad=True) for valid_pag in valid_pags]\n",
        "train_input_ids = np.array(train_input_ids)\n",
        "valid_input_ids = np.array(valid_input_ids)\n",
        "test_input_ids = np.array(test_input_ids)\n",
        "\n",
        "train_pad_labels = pad_sequences(train_labels, maxlen=max_paragraph_leng, padding='post', truncating='post', value=pad_id)\n",
        "valid_pad_labels = pad_sequences(valid_labels, maxlen=max_paragraph_leng, padding='post', truncating='post', value=pad_id)\n",
        "test_pad_labels = pad_sequences(test_labels, maxlen=max_paragraph_leng, padding='post', truncating='post', value=pad_id)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1TiFzLUuLUH"
      },
      "source": [
        "### Word-level 2xBi-LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox2UjeTGMGca"
      },
      "source": [
        "def categorical_crossentropy_loss(y_actual, y_pred):\n",
        "  \"\"\"\n",
        "    Custom Categorical Crossentropy Loss function.\n",
        "  \"\"\"\n",
        "  one_hot_correct = tf.one_hot(y_actual, depth=len(punctuation_marks), dtype=tf.float32)\n",
        "  log_pred = tf.keras.backend.log(y_pred)\n",
        "  per_example_loss = - tf.reduce_sum(log_pred * one_hot_correct, axis=[-1])\n",
        "  positions_mask = tf.cast(tf.not_equal(y_actual, pad_id), tf.float32)\n",
        "  loss_correct = tf.reduce_sum(per_example_loss * positions_mask, axis=[-1]) / (tf.reduce_sum(positions_mask, axis=[-1]) + 1e-5)\n",
        "  return loss_correct\n",
        "  "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIUj0wtQeT0d",
        "outputId": "e3ae13b7-62e1-46bb-ba9f-81ae1472077a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# Punctuation prediction model\n",
        "\n",
        "# load model in TPU scope\n",
        "with strategy.scope():\n",
        "  # Initialize model\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Input(shape=(max_paragraph_leng,)))\n",
        "  model.add(tf.keras.layers.Embedding(VOCAB_WORD_SIZE, WORD_EMBEDDING_SIZE))\n",
        "  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)))\n",
        "  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)))\n",
        "  model.add(tf.keras.layers.Dense(len(punctuation_marks), activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss=categorical_crossentropy_loss)           # build model. Note: Must compile model in TPU scope. However, must call fit function out of scope\n",
        "\n",
        "\n",
        "# Train\n",
        "model.summary()\n",
        "model.fit(train_input_ids, train_pad_labels, batch_size=batch_size, epochs=10, validation_data=(valid_input_ids, valid_pad_labels))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 128, 512)          30720000  \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 128, 256)          656384    \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 128, 256)          394240    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128, 7)            1799      \n",
            "=================================================================\n",
            "Total params: 31,772,423\n",
            "Trainable params: 31,772,423\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "  1/179 [..............................] - ETA: 7:20 - loss: 1.9465WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0392s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0392s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "179/179 [==============================] - ETA: 0s - loss: 0.5103WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "179/179 [==============================] - 15s 84ms/step - loss: 0.5103 - val_loss: 0.3565\n",
            "Epoch 2/10\n",
            "179/179 [==============================] - 8s 45ms/step - loss: 0.3309 - val_loss: 0.3093\n",
            "Epoch 3/10\n",
            "179/179 [==============================] - 8s 45ms/step - loss: 0.2947 - val_loss: 0.2913\n",
            "Epoch 4/10\n",
            "179/179 [==============================] - 8s 46ms/step - loss: 0.2704 - val_loss: 0.2835\n",
            "Epoch 5/10\n",
            "179/179 [==============================] - 8s 46ms/step - loss: 0.2487 - val_loss: 0.2686\n",
            "Epoch 6/10\n",
            "179/179 [==============================] - 8s 46ms/step - loss: 0.2288 - val_loss: 0.2654\n",
            "Epoch 7/10\n",
            "179/179 [==============================] - 8s 46ms/step - loss: 0.2105 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "179/179 [==============================] - 9s 49ms/step - loss: 0.1938 - val_loss: 0.2600\n",
            "Epoch 9/10\n",
            "179/179 [==============================] - 8s 46ms/step - loss: 0.1777 - val_loss: 0.2642\n",
            "Epoch 10/10\n",
            "179/179 [==============================] - 8s 46ms/step - loss: 0.1624 - val_loss: 0.2675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02f9a309b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAXJZqPGuGsg"
      },
      "source": [
        "### Evanluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5F_2oonFVV"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "def evaluate(y_actual, y_pred, average=None, is_logits=True):\n",
        "  \"\"\"\n",
        "    Compute accuracy for n-classes, exclude padding tokens\n",
        "  \"\"\"\n",
        "  if is_logits:\n",
        "    y_pred = tf.reshape(tf.cast(tf.argmax(y_pred, axis=-1), tf.float32), (-1, y_actual.shape[-1]))\n",
        "    y_pred = y_pred.numpy()\n",
        "  y_actual = y_actual.tolist()\n",
        "  pred_labels = y_pred.tolist()\n",
        "\n",
        "  seq_lens = []\n",
        "  not_pad_actual = []\n",
        "  for y_seq in y_actual:\n",
        "    cnt_len = 0\n",
        "    for tag in y_seq:\n",
        "      if tag != pad_id:\n",
        "        cnt_len += 1\n",
        "        not_pad_actual.append(tag)\n",
        "      else:\n",
        "        break\n",
        "    seq_lens.append(cnt_len)\n",
        "\n",
        "  pred_labels = [punctuation_marks[int(label)] for idx, labels in enumerate(pred_labels) for label in labels[:seq_lens[idx]]]\n",
        "  not_pad_actual = [punctuation_marks[label] for label in not_pad_actual]\n",
        "  report = classification_report(not_pad_actual, pred_labels, labels=['PERIOD', 'COMMA', 'COLON', 'QMARK', 'EXCLAM', 'SEMICOLON'], digits=4)\n",
        "\n",
        "  return report"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZJwmqk-iqxN",
        "outputId": "c7dee0e6-0993-4e3a-ad56-1d259da4891a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "pred_test = model.predict(test_input_ids)\n",
        "report = evaluate(test_pad_labels, pred_test, average=None, is_logits=True)\n",
        "\n",
        "print(report)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      PERIOD     0.5505    0.4536    0.4974     29643\n",
            "       COMMA     0.4540    0.3352    0.3856     21231\n",
            "       COLON     0.0000    0.0000    0.0000      1153\n",
            "       QMARK     0.7118    0.5158    0.5982      5271\n",
            "      EXCLAM     0.4798    0.4596    0.4695      9167\n",
            "   SEMICOLON     0.0000    0.0000    0.0000        43\n",
            "\n",
            "   micro avg     0.5217    0.4134    0.4613     66508\n",
            "   macro avg     0.3660    0.2940    0.3251     66508\n",
            "weighted avg     0.5128    0.4134    0.4569     66508\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwh2SFgxwAjC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}